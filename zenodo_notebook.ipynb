{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zenodo Automation\n",
    "\n",
    "-   Make sure to run the code cell below before testing out any functionalities.\n",
    "-   To test functionalities, look at cell 3 and onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Any\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Zenodo API Script\n",
    "\n",
    "A script to search Zenodo based on keywords and upload/download files.\n",
    "Usage: \n",
    "    - Search: python zenodo.py search keyword1 [keyword2 keyword3 ...]\n",
    "    - Download: python zenodo.py download record_id [output_dir]\n",
    "    - Download by Keywords: python zenodo.py download-via-keywords keyword1 [keyword2 ...] [output_dir]\n",
    "    - Upload: python zenodo.py upload filename [--title \"Title\"] [--description \"Description\"]\n",
    "\n",
    "Example: \n",
    "    python zenodo.py search climate\n",
    "    python zenodo.py search \"machine learning\" biology\n",
    "    python zenodo.py download 123456 ./downloads\n",
    "    python zenodo.py download-via-keywords climate data ./climate-downloads\n",
    "    python zenodo.py upload dataset.zip --title \"My Dataset\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def search_zenodo(keywords: List[str], page: int = 1, page_size: int = 20, sort: str = \"bestmatch\", access_token: Optional[str] = None) -> dict:\n",
    "        \"\"\"\n",
    "        Search Zenodo using keywords.\n",
    "        \n",
    "        Args:\n",
    "                keywords: List of keywords to search for\n",
    "                page: Page number to retrieve\n",
    "                page_size: Number of results per page\n",
    "                sort: Sorting method (bestmatch, mostrecent)\n",
    "                access_token: Optional Zenodo API access token\n",
    "                \n",
    "        Returns:\n",
    "                Dictionary containing the search results\n",
    "        \"\"\"\n",
    "        # Zenodo API endpoint for searching\n",
    "        zenodo_api_url = \"https://zenodo.org/api/records\"\n",
    "        \n",
    "        # Combine multiple keywords with AND operators\n",
    "        if len(keywords) > 1:\n",
    "                query = \" AND \".join(keywords)\n",
    "        else:\n",
    "                query = keywords[0]\n",
    "        \n",
    "        # Set up the parameters for the API request\n",
    "        params = {\n",
    "                \"q\": query,\n",
    "                \"size\": page_size,\n",
    "                \"page\": page,\n",
    "                \"sort\": sort\n",
    "        }\n",
    "        \n",
    "        # Set up headers with access token if provided\n",
    "        headers = {}\n",
    "        if access_token:\n",
    "                headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "        \n",
    "        # Make the API request\n",
    "        response = requests.get(zenodo_api_url, params=params, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "                return response.json()\n",
    "        else:\n",
    "                raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "\n",
    "def display_results(results: dict) -> None:\n",
    "        \"\"\"\n",
    "        Display the search results in a readable format.\n",
    "        \n",
    "        Args:\n",
    "                results: Dictionary containing the search results\n",
    "        \"\"\"\n",
    "        hits = results.get(\"hits\", {}).get(\"hits\", [])\n",
    "        total = results.get(\"hits\", {}).get(\"total\", 0)\n",
    "        \n",
    "        if isinstance(total, dict):  # Handle newer Zenodo API format\n",
    "                total = total.get(\"value\", 0)\n",
    "        \n",
    "        print(f\"\\nFound {total} results\\n\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        if not hits:\n",
    "                print(\"No results found for your search query.\")\n",
    "                return\n",
    "        \n",
    "        for i, hit in enumerate(hits, 1):\n",
    "                metadata = hit.get(\"metadata\", {})\n",
    "                \n",
    "                title = metadata.get(\"title\", \"No title\")\n",
    "                creators = metadata.get(\"creators\", [])\n",
    "                creator_names = \", \".join([creator.get(\"name\", \"Unknown\") for creator in creators])\n",
    "                publication_date = metadata.get(\"publication_date\", \"Unknown date\")\n",
    "                description = metadata.get(\"description\", \"No description\")\n",
    "                \n",
    "                # Truncate long descriptions\n",
    "                if len(description) > 200:\n",
    "                        description = description[:200] + \"...\"\n",
    "                \n",
    "                # Get DOI and URL\n",
    "                doi = metadata.get(\"doi\", \"No DOI\")\n",
    "                record_url = f\"https://zenodo.org/record/{hit.get('id', '')}\"\n",
    "                \n",
    "                print(f\"{i}. {title}\")\n",
    "                print(f\"   Authors: {creator_names}\")\n",
    "                print(f\"   Published: {publication_date}\")\n",
    "                print(f\"   DOI: {doi}\")\n",
    "                print(f\"   URL: {record_url}\")\n",
    "                \n",
    "                # Print keywords if available\n",
    "                if \"keywords\" in metadata and metadata[\"keywords\"]:\n",
    "                        print(f\"   Keywords: {', '.join(metadata['keywords'])}\")\n",
    "                        \n",
    "                print(f\"   Description: {description}\")\n",
    "                print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def save_results(results: dict, filename: str = \"zenodo_results.json\") -> None:\n",
    "        \"\"\"\n",
    "        Save the search results to a JSON file.\n",
    "        \n",
    "        Args:\n",
    "                results: Dictionary containing the search results\n",
    "                filename: Name of the file to save the results to\n",
    "        \"\"\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Results saved to {filename}\")\n",
    "\n",
    "\n",
    "def download_zenodo_record(record_id: str, output_dir: Optional[str] = None, access_token: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Download all files associated with a Zenodo record.\n",
    "        \n",
    "        Args:\n",
    "                record_id: The ID of the record to download files from\n",
    "                output_dir: Directory to save files to (default: current directory)\n",
    "                access_token: Zenodo API access token\n",
    "        \"\"\"\n",
    "        # Set up the output directory\n",
    "        if output_dir:\n",
    "                output_path = Path(output_dir)\n",
    "                output_path.mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "                output_path = Path.cwd()\n",
    "        \n",
    "        # Set up headers with access token if provided\n",
    "        headers = {}\n",
    "        if access_token:\n",
    "                headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "        \n",
    "        # Get record metadata\n",
    "        api_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "                raise Exception(f\"Failed to get record {record_id}: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        record_data = response.json()\n",
    "        title = record_data.get(\"metadata\", {}).get(\"title\", \"Unknown Title\")\n",
    "        print(f\"Downloading files for record: {title}\")\n",
    "        \n",
    "        # Extract file information\n",
    "        files = record_data.get(\"files\", [])\n",
    "        if not files:\n",
    "                print(\"No files found in this record.\")\n",
    "                return\n",
    "        \n",
    "        print(f\"Found {len(files)} file(s).\")\n",
    "        \n",
    "        # Download each file\n",
    "        for file_info in files:\n",
    "                file_url = file_info.get(\"links\", {}).get(\"self\", \"\")\n",
    "                filename = file_info.get(\"key\", \"unknown_file\")\n",
    "                size = file_info.get(\"size\", 0)\n",
    "                \n",
    "                # Format the file size\n",
    "                size_str = f\"{size / 1024:.1f} KB\" if size < 1024 * 1024 else f\"{size / (1024 * 1024):.1f} MB\"\n",
    "                \n",
    "                print(f\"Downloading: {filename} ({size_str})\")\n",
    "                \n",
    "                # Download the file with the same headers\n",
    "                file_response = requests.get(file_url, headers=headers, stream=True)\n",
    "                if file_response.status_code != 200:\n",
    "                        print(f\"Failed to download {filename}: {file_response.status_code}\")\n",
    "                        continue\n",
    "                \n",
    "                # Sanitize filename to remove path separators\n",
    "                safe_filename = filename.replace('/', '_').replace('\\\\', '_')\n",
    "                \n",
    "                # Save the file\n",
    "                output_file = output_path / safe_filename\n",
    "                with open(output_file, 'wb') as f:\n",
    "                        for chunk in file_response.iter_content(chunk_size=8192):\n",
    "                                f.write(chunk)\n",
    "                \n",
    "                print(f\"Saved to: {output_file}\")\n",
    "\n",
    "def download_via_keywords(\n",
    "    keywords: List[str], \n",
    "    output_dir: Optional[str] = None, \n",
    "    access_token: Optional[str] = None,\n",
    "    max_records: int = 10,\n",
    "    page_size: int = 20,\n",
    "    sort: str = \"bestmatch\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Search for records matching keywords and download all files from those records.\n",
    "    \n",
    "    Args:\n",
    "        keywords: List of keywords to search for\n",
    "        output_dir: Directory to save files to (default: current directory)\n",
    "        access_token: Zenodo API access token\n",
    "        max_records: Maximum number of records to download\n",
    "        page_size: Number of results per page\n",
    "        sort: Sorting method (bestmatch, mostrecent)\n",
    "    \"\"\"\n",
    "    # Set up the output directory\n",
    "    if output_dir:\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        output_path = Path.cwd()\n",
    "    \n",
    "    print(f\"Searching Zenodo for: {' AND '.join(keywords)}\")\n",
    "    \n",
    "    # Perform the search\n",
    "    results = search_zenodo(keywords, 1, page_size, sort, access_token)\n",
    "    \n",
    "    hits = results.get(\"hits\", {}).get(\"hits\", [])\n",
    "    total = results.get(\"hits\", {}).get(\"total\", 0)\n",
    "    \n",
    "    if isinstance(total, dict):  # Handle newer Zenodo API format\n",
    "        total = total.get(\"value\", 0)\n",
    "    \n",
    "    if not hits:\n",
    "        print(\"No results found for your search query.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {total} results. Will download files from up to {max_records} records.\\n\")\n",
    "    \n",
    "    # Limit the number of records to download\n",
    "    records_to_download = min(len(hits), max_records)\n",
    "    \n",
    "    # Create a subdirectory for each record\n",
    "    for i, hit in enumerate(hits[:records_to_download], 1):\n",
    "        record_id = hit.get(\"id\", \"\")\n",
    "        if not record_id:\n",
    "            continue\n",
    "        \n",
    "        # Create a directory for this record\n",
    "        record_title = hit.get(\"metadata\", {}).get(\"title\", f\"record_{record_id}\")\n",
    "        safe_title = \"\".join(c if c.isalnum() or c in \"._- \" else \"_\" for c in record_title)\n",
    "        safe_title = safe_title[:50]  # Limit directory name length\n",
    "        \n",
    "        record_dir = output_path / f\"{i}_{safe_title}\"\n",
    "        record_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save record metadata\n",
    "        with open(record_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(hit, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Download all files for this record\n",
    "        try:\n",
    "            print(f\"\\nDownloading record {i}/{records_to_download}: {record_title}\")\n",
    "            download_zenodo_record(record_id, str(record_dir), access_token)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading record {record_id}: {e}\")\n",
    "    \n",
    "    print(f\"\\nDownload complete. Files saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Records\n",
    "\n",
    "To search and display results:\n",
    "-   add and place the words with your keywords that you want to search by in the list called keywords \n",
    "-   To search for records, call the function:\n",
    "-   ```search_result(keywords)``` function takes in a list of keywords\n",
    "\n",
    "-   To display the searched results, call the function:\n",
    "-   ```display_results(results)``` function takes in dictionary of all the results produced from the search and displays them\n",
    "\n",
    "-   run the cell below to test search functionality; if cell produces error, make sure to run the first cell on the top of this notebook\n",
    "-   the command line equivalent ran in the terminal is:\n",
    "\n",
    "        python zenodo.py search <keywords you want to search by>\n",
    "\n",
    "-   Ex:\n",
    "\n",
    "        python zenodo.py search climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 31039 results\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1. DDF_test_data\n",
      "   Authors: Hartick, Carl\n",
      "   Published: 2024-11-05\n",
      "   DOI: 10.5281/zenodo.14041129\n",
      "   URL: https://zenodo.org/record/14041129\n",
      "   Description: No description\n",
      "--------------------------------------------------------------------------------\n",
      "2. The UK Climate Predicition 2009 (UKCP09) Outputs and metadata specification - Release 1.1\n",
      "   Authors: Stephens, Ag\n",
      "   Published: 2014-01-02\n",
      "   DOI: 10.5281/zenodo.7356959\n",
      "   URL: https://zenodo.org/record/7356959\n",
      "   Keywords: data and information\n",
      "   Description: The UK Climate Predicition 2009 (UKCP09) Project user interface (UI) documentation. The User Interface (UI) provides the access to project outputs. These outputs must also be consistent and well-descr...\n",
      "--------------------------------------------------------------------------------\n",
      "3. Data-4-Climate-Action-Edinburgh/Data4ClimateActionEdinburgh_Code_etc: Data from 2022 survey\n",
      "   Authors: data4climateactionedinburgh\n",
      "   Published: 2023-06-12\n",
      "   DOI: 10.5281/zenodo.8030084\n",
      "   URL: https://zenodo.org/record/8030084\n",
      "   Description: <p>Results of the one-day survey carried out on the D4CAE stall at the 2022 Edinburgh Climate Festival.</p>\n",
      "--------------------------------------------------------------------------------\n",
      "4. Usability of Medium Resolution Optical Remote Sensing Images for Anomaly Detection in Maritime Surveillance Applications\n",
      "   Authors: Schwarz, Egbert, Voinov, Sergey, Krause, Detmar\n",
      "   Published: 2022-10-04\n",
      "   DOI: 10.5281/zenodo.7148919\n",
      "   URL: https://zenodo.org/record/7148919\n",
      "   Keywords: remote sensing, anomaly, object detection\n",
      "   Description: <p>As part of the project &quot;Intelligent Assistance and&nbsp;Analysis Systems for Early Detection and Management of&nbsp;Maritime Hazardous Situations&rdquo; (IntelliMar) an anomaly&nbsp;detection ...\n",
      "--------------------------------------------------------------------------------\n",
      "5. An Approach of Sustainable Development Model for Water Security in Growing Cities\n",
      "   Authors: Nepal, Ganga Data\n",
      "   Published: 2023-01-09\n",
      "   DOI: 10.5281/zenodo.7519299\n",
      "   URL: https://zenodo.org/record/7519299\n",
      "   Keywords: Investment, sustainable, degradation, infrastructure, and mitigation\n",
      "   Description: <p>To address the growing water crisis, proper water resources management: realistic planning, and investment in water and sanitation can only achieve the Sustainable Development Goals (SDG) 2030. In ...\n",
      "--------------------------------------------------------------------------------\n",
      "6. The UK Climate Prediction 2009 (UKCP09) Threshold Detector Manual v1.2.0\n",
      "   Authors: Stephens, Ag, Bowyer, Paul, Milin, Sophie\n",
      "   Published: 2011-06-15\n",
      "   DOI: 10.5281/zenodo.7356957\n",
      "   URL: https://zenodo.org/record/7356957\n",
      "   Description: The UK Climate Prediction 2009 (UKCP09) Threshold Detector Manual provides supporting information on detecting thresholds in the UKCP09 datasets.\n",
      "--------------------------------------------------------------------------------\n",
      "7. Climate Pledge Ideas\n",
      "   Authors: MacRae, Molly\n",
      "   Published: 2024-06-19\n",
      "   DOI: 10.5281/zenodo.12168393\n",
      "   URL: https://zenodo.org/record/12168393\n",
      "   Description: <p>This is a poster made for Harwell Open Week 2024 which highlights different pledges we can take that will help cut emisions and tackle climate change.</p>\n",
      "<p>Feel free to share this poster as much ...\n",
      "--------------------------------------------------------------------------------\n",
      "8. Opportunity Brief: Look to the Local: Data and engagement in environmental and climate planning\n",
      "   Authors: Williams, Emelia, Hoeberling, Katie\n",
      "   Published: 2022-04-27\n",
      "   DOI: 10.5281/zenodo.6516003\n",
      "   URL: https://zenodo.org/record/6516003\n",
      "   Keywords: open data, environmental policy, climate planning, local governance\n",
      "   Description: <p>This opportunity brief focuses on the utility of environmental data and processes and procedures of local community engagement within environmental and climate topics. By leveraging openness to sup...\n",
      "--------------------------------------------------------------------------------\n",
      "9. EVIDENT H2020– Environmental data for Sweden cities Dataset\n",
      "   Authors: Sidiras, George, Ioannidis, Dimosthenis\n",
      "   Published: 2023-05-09\n",
      "   DOI: 10.5281/zenodo.7912833\n",
      "   URL: https://zenodo.org/record/7912833\n",
      "   Keywords: Environmental data , weather Sweden, Swedish climate data, Sweden weather data, Sweden temperature data, Sweden humidity data,Swedish meteorological data, Sweden city climate data,Dataset of environmental data for 700 Swedish cities\n",
      "   Description: <p>EVIDENT H2020- Environmental data for Swedish Cities Dataset</p>\n",
      "\n",
      "<p>Environmental data from 615 cities in Sweden</p>\n",
      "\n",
      "<p>Weather, in combination with residential characteristics and electricity co...\n",
      "--------------------------------------------------------------------------------\n",
      "10. C3-EURO4M-MEDARE Mediterranean historical climate data - v.2\n",
      "   Authors: Centre for Climate Change / URV\n",
      "   Published: 2015-04-09\n",
      "   DOI: 10.5281/zenodo.16702\n",
      "   URL: https://zenodo.org/record/16702\n",
      "   Keywords: historical climate data rescue, meteorological stations, daily maximum temperature, daily minimum temperature, daily precipitation, hourly air pressure, Mediterranean, North Africa, Middle East\n",
      "   Description: <p>Historical surface climate data files and meta-data for stations in Mediterranean North Africa and Middle East areas (1852-2008).</p>\n",
      "--------------------------------------------------------------------------------\n",
      "11. Keep or delete data?  - A decision guide\n",
      "   Authors: Anders, Ivonne, Lammert, Andrea, Löhden, Aenne, Peters-von Gehlen, Karsten\n",
      "   Published: 2024-04-01\n",
      "   DOI: 10.5281/zenodo.10902277\n",
      "   URL: https://zenodo.org/record/10902277\n",
      "   Keywords: data deletion, data preservation, guidance, data management\n",
      "   Description: <p>Data is of great importance in both private and professional environments, as it is essential for communication, organisation, entertainment, business decisions, innovation and security. &nbsp;Data...\n",
      "--------------------------------------------------------------------------------\n",
      "12. Towards increasing the reusability of atmospheric model data: adapting metadata standards and introducing quality criteria\n",
      "   Authors: Peters, Karsten, Neumann, Daniel, Thiemann, Hannes\n",
      "   Published: 2020-02-14\n",
      "   DOI: 10.5281/zenodo.3667635\n",
      "   URL: https://zenodo.org/record/3667635\n",
      "   Keywords: metadata, quality, DataCite, atmospheric science, CMIP, CMIP6, standardization, project, atmospheric modeling, respository, data archival, FAIR, atmodat\n",
      "   Description: <p>We present current and future work at the German Climate Computing Center (DKRZ) aimed at increasing the long-term reusability of atmospheric and climate model data. Specifically the recently funde...\n",
      "--------------------------------------------------------------------------------\n",
      "13. D6.1 Data Management Plan\n",
      "   Authors: Euro-Mediterranean Center for Climate Change\n",
      "   Published: 2023-08-02\n",
      "   DOI: 10.5281/zenodo.14195984\n",
      "   URL: https://zenodo.org/record/14195984\n",
      "   Description: <p><span>The CAPABLE project will produce a number of data sets for internal and public use. This Data Management Plan (DMP) describes the data management life cycle for the data to be collected, proc...\n",
      "--------------------------------------------------------------------------------\n",
      "14. Collecting and Preserving Local and Traditional Climate Knowledge\n",
      "   Authors: Collins, Julia, Pulsifer, Peter L., Gearheard, Shari\n",
      "   Published: 2011-10-25\n",
      "   DOI: 10.5281/zenodo.34972\n",
      "   URL: https://zenodo.org/record/34972\n",
      "   Keywords: local knowledge, Arctic, climate\n",
      "   Description: <p>The Exchange for Local Observations and Knowledge of the Arctic (ELOKA)&nbsp;facilitates the collection, preservation, exchange, and use of local observations and knowledge of the Arctic. Local and...\n",
      "--------------------------------------------------------------------------------\n",
      "15. C3-EURO4M-MEDARE Mediterranean historical climate data\n",
      "   Authors: Centre for Climate Change / URV\n",
      "   Published: 2013-11-04\n",
      "   DOI: 10.5281/zenodo.7531\n",
      "   URL: https://zenodo.org/record/7531\n",
      "   Keywords: historical climate data rescue, meteorological stations, daily maximum temperature, daily minimum temperature, daily precipitation, hourly air pressure, Mediterranean, North Africa, Middle East\n",
      "   Description: <p>Historical surface climate data files and meta-data for stations in Mediterranean North Africa and Middle East areas (1852-2008)</p>\n",
      "--------------------------------------------------------------------------------\n",
      "16. Outputs of the Jupyter Notebook - Deep learning and variational inversion to quantify and attribute climate change (CIRC23)\n",
      "   Authors: Environmental Data Science book Community\n",
      "   Published: 2023-08-24\n",
      "   DOI: 10.5281/zenodo.8279575\n",
      "   URL: https://zenodo.org/record/8279575\n",
      "   Keywords: environmental data science, climate science, modelling, reproducibility challenge\n",
      "   Description: <p>The dataset contains the outputs of the notebook &quot;Deep learning and variational inversion to quantify and attribute climate change (CIRC23)&quot;&nbsp;published in The Environmental Data Scien...\n",
      "--------------------------------------------------------------------------------\n",
      "17. High-resolution gridded climate data for Europe based on bias-corrected EURO-CORDEX: the ECLIPS-2.0 dataset\n",
      "   Authors: Chakraborty Debojyoti, Dobor laura, Zolles Anita, Hlásny Tomáš, Schueler Silvio\n",
      "   Published: 2020-07-20\n",
      "   DOI: 10.5281/zenodo.3952159\n",
      "   URL: https://zenodo.org/record/3952159\n",
      "   Keywords: Bias corrected,, EURO-CORDEX, 30-arc sec, Climate data\n",
      "   Description: <p>We developed a new climate dataset for Europe referred to as ECLIPS (European CLimate Index ProjectionS), which contains gridded data for 80 annual, seasonal, and monthly climate variables for two ...\n",
      "--------------------------------------------------------------------------------\n",
      "18. Multilingual Structured Climate Research Data in Wikidata - The Community Perspective\n",
      "   Authors: Sarasua, Cristina, Mietchen, Daniel\n",
      "   Published: 2020-08-21\n",
      "   DOI: 10.5281/zenodo.3994272\n",
      "   URL: https://zenodo.org/record/3994272\n",
      "   Keywords: Wikidata, Linked open data, FAIR data, Collaboration, Data science, Climate research, Community curation, SPARQL\n",
      "   Description: <p>This repo hosts a presentation &quot;Multilingual Structured Climate Research Data in Wikidata - The Community Perspective&quot;, which is a contribution to the Workshop &quot;<a href=\"https://wcr....\n",
      "--------------------------------------------------------------------------------\n",
      "19. TG-Data Recommendations for AR7\n",
      "   Authors: Intergovernmental Panel on Climate Change\n",
      "   Published: 2023-10-31\n",
      "   DOI: 10.5281/zenodo.10059282\n",
      "   URL: https://zenodo.org/record/10059282\n",
      "   Description: No description\n",
      "--------------------------------------------------------------------------------\n",
      "20. Trusted Data Services to Support Climate Change Research\n",
      "   Authors: Sandy Harrison, Erik Kjellström, Barbara Ryan, Julian Meyer-Arnek, Giulia Ajmone Marsan, Robert Chen, Marko Komac, Michael Böttinger, Mark Parsons, Juanle Wang, Lynn Yarmey\n",
      "   Published: 2015-07-06\n",
      "   DOI: 10.5281/zenodo.34377\n",
      "   URL: https://zenodo.org/record/34377\n",
      "   Keywords: Climate change, Data stewardship, Open data, Open science\n",
      "   Description: <p>Abstract booklet of the side event convened by the World Data System ahead of the premier climate science conference leading to COP21.</p>\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "keywords = [\"climate\", \"data\"]\n",
    "search_results = search_zenodo(keywords)\n",
    "display_results(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Search Results\n",
    "\n",
    "-   ```save_results(search_results, filename=\"fileName\")``` function takes in a dictiionary of results from the search and json filename\n",
    "-   if the filename doesn't exist, a file of that name will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to climate_data_results.json\n"
     ]
    }
   ],
   "source": [
    "save_results(search_results, filename=\"climate_data_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Records via Record IDs\n",
    "\n",
    "-   To find the record ID, its the numbers at the end of each record URL\n",
    "    -   Ex: if the url is https://zenodo.org/record/8030084 then the record ID is 8030084\n",
    "\n",
    "-   Each record URL is displayed when a search is done and the results are displayed, as explained in the cells above\n",
    "-   To download a record via record ID, call the function:\n",
    "-   ```download_zenodo_record(record_id)``` where it takes in the record ID as a string for the first parameter \n",
    "\n",
    "Optional:\n",
    "-   To store the downloaded record in a directory, pass it as a string as the second parameter in the function \n",
    "    -   Ex: \n",
    "\n",
    "            download_zenodo_record(record_id, output_dir=output_directory)\n",
    "\n",
    "-   run the cell below to test search functionality; if cell produces error, make sure to run the first cell on the top of this notebook\n",
    "-   the command line equivalent ran in the terminal is:\n",
    "\n",
    "        python zenodo.py download <database id> <optional: directory you want to download to>\n",
    "\n",
    "-   Ex: \n",
    "\n",
    "        python zenodo.py download 13960343 ./downloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files for record: The UK Climate Predicition 2009 (UKCP09) Outputs and metadata specification - Release 1.1\n",
      "Found 1 file(s).\n",
      "Downloading: UKCP09_file_format_spec.pdf (450.3 KB)\n",
      "Saved to: downloads/UKCP09_file_format_spec.pdf\n"
     ]
    }
   ],
   "source": [
    "record_id = \"7356959\"  \n",
    "output_directory = \"./downloads\" \n",
    "\n",
    "download_zenodo_record(record_id, output_dir=output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Records via Keywords\n",
    "\n",
    "-   To download a record via keywords, call the function:\n",
    "-   ```download_via_keywords(keywords)``` where it takes in a list of strings of keywords as the first parameter\n",
    "\n",
    "Optional:\n",
    "-   To store the downloaded record in a directory, pass it as a string as the second parameter in the function \n",
    "-   To download a max number of records, pass the max number of records you want to download as the third parameter\n",
    "-   To download the top results sorted by \"bestmatch\" or \"mostrecent\", pass either as a string as the fourth parameter\n",
    "    -   Ex: \n",
    "            download_via_keywords(keywords, output_dir=output_directory, max_records=5,sort=\"bestmatch\")\n",
    "\n",
    "-   run the cell below to test search functionality; if cell produces error, make sure to run the first cell on the top of this notebook\n",
    "\n",
    "-   the command line equivalent ran in the terminal is:\n",
    "\n",
    "        python zenodo.py download-via-keywords <keyword1> <keyword2> <keyword3> <...> \n",
    "\n",
    "-   Ex: \n",
    "\n",
    "        python zenodo.py download-via-keywords \"machine learning\" climate temperature dataset\n",
    "\n",
    "Optional (directory, max downloads, sort):\n",
    "\n",
    "        python zenodo.py download-via-keywords \"machine learning\" climate temperature dataset --max-records 5 --sort bestmatch ./climate_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Zenodo for: climate AND data\n",
      "\n",
      "Found 31040 results. Will download files from up to 2 records.\n",
      "\n",
      "\n",
      "Downloading record 1/2: DDF_test_data\n",
      "Downloading files for record: DDF_test_data\n",
      "Found 8 file(s).\n",
      "Downloading: events_2021070800-2021083123_T5.csv (0.8 KB)\n",
      "Saved to: downloads/1_DDF_test_data/events_2021070800-2021083123_T5.csv\n",
      "Downloading: 2021_2021_DDF.nc (19.0 KB)\n",
      "Saved to: downloads/1_DDF_test_data/2021_2021_DDF.nc\n",
      "Downloading: objects_08.tar (23.6 MB)\n",
      "Saved to: downloads/1_DDF_test_data/objects_08.tar\n",
      "Downloading: 2021_2021_KO_params.nc (23.8 KB)\n",
      "Saved to: downloads/1_DDF_test_data/2021_2021_KO_params.nc\n",
      "Downloading: 2021_iams.nc (18.7 KB)\n",
      "Saved to: downloads/1_DDF_test_data/2021_iams.nc\n",
      "Downloading: dummy_data.nc (47.6 KB)\n",
      "Saved to: downloads/1_DDF_test_data/dummy_data.nc\n",
      "Downloading: objects_202107080000-202108312300_T5.csv (130.8 KB)\n",
      "Saved to: downloads/1_DDF_test_data/objects_202107080000-202108312300_T5.csv\n",
      "Downloading: objects_07.tar (19.8 MB)\n",
      "Saved to: downloads/1_DDF_test_data/objects_07.tar\n",
      "\n",
      "Downloading record 2/2: The UK Climate Predicition 2009 (UKCP09) Outputs and metadata specification - Release 1.1\n",
      "Downloading files for record: The UK Climate Predicition 2009 (UKCP09) Outputs and metadata specification - Release 1.1\n",
      "Found 1 file(s).\n",
      "Downloading: UKCP09_file_format_spec.pdf (450.3 KB)\n",
      "Saved to: downloads/2_The UK Climate Predicition 2009 _UKCP09_ Outputs a/UKCP09_file_format_spec.pdf\n",
      "\n",
      "Download complete. Files saved to downloads\n"
     ]
    }
   ],
   "source": [
    "keywords = [\"climate\", \"data\"]\n",
    "output_directory = \"./downloads\"\n",
    "download_via_keywords(keywords, output_dir=output_directory, max_records=2,sort=\"bestmatch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
